# Data Scientist

Experienced data scientist with a strong background in machine learning, statistical analysis, and data visualization. Proficient in Python, R,
and SQL with a solid understanding of big data technologies like Hadoop and Spark. Demonstrated ability to work with stakeholders to
identify business problems, develop data-driven solutions, and communicate insights through compelling visualizations and reports.
Passionate about using data to drive impactful decision-making and continuously seeking new challenges to expand technical and business
acumen

#### Technical Skills

 - **Frameworks**: Spark, Ambari, Kafka, Presto, Airflow
 - **Database**: PL/SQL, Hadoop, SAP Hana, PostgreSQL, InfluxDB
 - **Languages**: Scala, Python, R
 - **Tools**: Git, Google Cloud Platform, Azure Cloud Platform, Microsoft Office 365
 - **IDE**: IntelliJ Idea, VSCode, JupyterHub, Databricks
 - **Visualization** Tools: Grafana, PowerBI, Tableau, Miro
 - **Soft Skills**: Scrum Kanban, Agile, Jira, Critical Thinking, Leadership

## Education	

- M.S., Data Science, Dept. of Mathematics	| University of Essex | Distinction (_Oct 2022_)	 			        		
- B.E., Information Technology | Savitribai Phule Pune University | 60.05% (_May 2020_)
- 12th., Science | Deogiri College | 72.07% (_2015_)
- 10th., High School | St. Johns High School | 84.36% (_2013_)

## Work Experience

**Data Scientist @ Cloudfm | Mindsett (_January 2021 - Present_)**
- Visualised data using Graffana and PowerBI.
- Used Azure Data Studio to manage and work through the database.
- Using Azure DevOps to manage repositories.
- Using Jira, Miro and Monday.com for project collaboration.
- Used R and Python to work on predictive maintenance projects.
- Working on Asset Health Performance Indicator Metric using Weibull Distribution and chi-square.
- Collaborated on a project that detects the on-off and working time of the asset.
- Delivered automated report solutions for end users which involved the use of various Python functionalities.
- Using Airflow and Databricks to do ETL processes on Pyspark and Python pipelines.
- Worked on time-series data and used tools necessary to perform PCA.

**Data Analyst @ Reliance Jio Platform (_December 2020 - Aug 2021_)**
-	Delivered business outputs using Scala on the Spark framework
-	Derived data from source points using Hive, SAP Tools like SAP Hana and PL/SQL
-	Provided end-to-end solutions for data needs of business using Kafka, API, JSON
-	Collaborated with my peers to develop solutions using Git 
-	Delivered streaming data to businesses using Apache Flink 
-	Used Airflow to deploy DAGs using the Python language
-	Managed and assessed data of everyday business queries using Ambari 
-	Mentored juniors to use tools and languages such as IntelliJ, Git, Shell, Scala, etc.

**Android Developer Intern @ VEM Tooling (_June 2019 - April 2020_)**
-	Built an Android application of size less than 1.5 MB
-	Deployed application on Google Playstore
-	Developed a machine learning model for the detection of butterfly species (accuracy >70%)
-	Used TensorFlow and CNN algorithm to build the model
-	Formed Structured Dataset and curated the set of Butterfly species
-	Created a game that rewards users with Coupons in the form of a QR code.
- Set up Admin application to manage data of users and Scan QR codes.

## Certifications


## Certifications
- [Data Science Blog](https://medium.com/@shazank)
